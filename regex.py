# -*- coding: utf-8 -*-
"""TASK5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vXeUynEW0D-ibVQrpqwOyJcB24tpjXMr
"""

import json
import os

# Installing the Kaggle package
!pip install kaggle 

!mkdir /root/.kaggle/ 

#Important Note: complete this with your own key - after running this for the first time remmember to **remove** your API_KEY
api_token = {"username":"ronbeiden1","key":"23dd6c93f49ccbda00a96b20dfcd43b5"}


# creating kaggle.json file with the personal API-Key details 
# You can also put this file on your Google Drive
with open('/root/.kaggle/kaggle.json', 'w') as file:
  json.dump(api_token, file)
!chmod 600 /root/.kaggle/kaggle.json

!mkdir ./datasets
!!mkdir ./datasets/BlogAuthorshipCorpus
!mkdir ./datasets/UFOSightings

!kaggle datasets download -d rtatman/blog-authorship-corpus -p ./datasets/BlogAuthorshipCorpus
!chdir ./datasets/BlogAuthorshipCorpus
!unzip ./datasets/BlogAuthorshipCorpus/*.zip  -d ./datasets/BlogAuthorshipCorpus
!ls ./datasets/BlogAuthorshipCorpus

!kaggle datasets download -d NUFORC/ufo-sightings -p ./datasets/UFOSightings
!chdir ./datasets/UFOSightings
!unzip ./datasets/UFOSightings/*.zip  -d ./datasets/UFOSightings
!ls ./datasets/UFOSightings

import pandas as pd
import numpy as np
import re 
import datetime 
from datetime import datetime 
import calendar
dfÖ¹_complete = pd.read_csv('/content/datasets/UFOSightings/complete.csv',error_bad_lines=False)
df_scrubbed = pd.read_csv('/content/datasets/UFOSightings/scrubbed.csv',error_bad_lines=False)
df_blogtext= pd.read_csv("/content/datasets/BlogAuthorshipCorpus/blogtext.csv",error_bad_lines=False)

"""#**Blog Authorship Corpus**

#**Q1**
"""

df1 = df_blogtext[["sign","text"]].copy()
regex = re.compile("(\w{8,})")
df1["count"] = df1["text"].apply(lambda t: len(regex.findall(t)))
df_check = df1.groupby("sign")["count"].count().to_frame("")
max_word = max(df_check[""])
max_sign = df_check[df_check[""] == max_word]
max_sign

"""#**Q2**"""

months = ["January","February","March","April","May","June","July","August","September","October","November","December"]
dfday = df_blogtext["date"].copy()
dfday = dfday.apply(lambda x: x.split(","))
dfday = dfday.to_frame()
dfday["month"] = dfday["date"].apply(lambda x:x[1])
dfday = dfday[dfday["month"].isin(months)]
dfday = dfday["date"]
dfday = dfday.apply(lambda x : x[0] + " " + x[1] + ' ' + x[2])
dfday = dfday.apply(lambda x : datetime.strptime(x,"%d %B %Y"))
dfday = dfday.apply(lambda x : datetime.weekday(x))
dfday = dfday.to_frame()
dfsum = dfday.groupby("date",as_index=False)["date"].count()
dfsum_fix = dfsum.rename(index={0:'Monday', 1:"Tuesday", 2:"Wednesday", 3:"Thursday", 4:"Friday", 5:"Saturday", 6:"Sunday"})
dfsum_fix

"""#**Q3**"""

df_valid_mail = df_blogtext[["topic", "text"]].copy()
regex = re.compile("(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&*'+/=?^_`{|}~-]+)*|(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*)@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])")
df_valid_mail["mail"] = df_valid_mail["text"].apply(lambda x: len(regex.findall(x)))
dfmail = df_valid_mail.groupby("topic")["mail"].sum().to_frame("")
dfmail

"""#**Q4**"""

df_id = df_blogtext[["id", "text"]].copy()
res = re.compile("(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\.[a-z0-9!#$%&*'+/=?^_`{|}~-]+)*|(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21\x23-\x5b\x5d-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])*)@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\[(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?|[a-z0-9-]*[a-z0-9]:(?:[\x01-\x08\x0b\x0c\x0e-\x1f\x21-\x5a\x53-\x7f]|\\[\x01-\x09\x0b\x0c\x0e-\x7f])+)\])")
df_id["mail"] = df_id["text"].apply(lambda x: len(res.findall(x)))
df_id = df_id.groupby("id")["mail"].sum().to_frame("")
dfmail = max(df_id[""])
max_id = df_id[df_id[""] == dfmail]
max_id

"""#**Q5**"""

df_longest_num = df_blogtext[["topic","text"]].copy()
res = re.compile("[\d,]+")
def longest(t):
  r = res.findall(t)
  long_list = [] 
  if not r:
    return 0 
  for i in r :
    long_list.append(len(i))
  return max(long_list)
df_longest_num["number"] = df_longest_num["text"].apply(lambda x:(longest(x)))
max_long = max(df_longest_num["number"])
max_len = df_longest_num[df_longest_num["number"] == max_long]
max_len

"""#**UFO Sightings**

#**Q1**
"""

def num_of_scouts(country, year):
  df_scouts = df_scrubbed[["country", "datetime"]].copy()
  df_scouts = df_scouts.fillna("")
  def extract_year(date_time):
    year = date_time.year
    return year
  df_scouts["datetime"] = pd.to_datetime(df_scouts["datetime"], errors="coerce")
  df_scouts["Year"] = df_scouts["datetime"].apply(lambda x: extract_year(x))
  df_scouts = df_scouts[df_scouts["country"] == country]
  def int_none_to_zero(x):
    if np.isnan(x):
      x = np.nan_to_num(x)
    return x
  df_scouts["Year"] = df_scouts["Year"].apply(lambda x: int_none_to_zero(x))
  df_scouts["Year"] = df_scouts["Year"].apply(lambda x: int(x))
  df_scouts = df_scouts[df_scouts["Year"] == year]
  df_scouts_function = df_scouts.groupby(["Year","country"])["datetime"].count().to_frame("")
  return df_scouts_function
num_of_scouts("us", 1910)

"""#**Q2**"""

df_m_scout= df_scrubbed[["datetime"]].copy()
df_m_scout= df_m_scout.fillna("")
df_m_scout["datetime"] = pd.to_datetime(df_m_scout["datetime"],errors="coerce")
def extract_month(date_time):
  x = date_time.month
  return x
df_m_scout["Month"] =  df_m_scout["datetime"].apply(lambda x : extract_month(x))
def int_none_to_zero(x):
  if np.isnan(x):
    x = np.nan_to_num(x)
  return x
df_m_scout["Month"] =  df_m_scout["Month"].apply(lambda x: int_none_to_zero(x))
df_m_scout["Month"] =  df_m_scout["Month"].apply(lambda x: int(x))
df_m_scout = df_m_scout[df_m_scout["Month"] > 0]
df_max_month = df_m_scout.groupby("Month")["Month"].count().to_frame("")
max_month = max(df_max_month[""])
maxMonth = df_max_month[df_max_month[""] == max_month]
maxMonth

"""#**Q3**"""

df_m_scout= df_scrubbed[["datetime"]].copy()
df_m_scout= df_m_scout.fillna("")
df_m_scout["datetime"] = pd.to_datetime(df_m_scout["datetime"],errors="coerce")
def extract_hour(date_time):
  x = date_time.hour
  return x
df_m_scout["Hour"] =  df_m_scout["datetime"].apply(lambda x : extract_hour(x))
def int_none_to_zero(x):
  if np.isnan(x):
    x = np.nan_to_num(x)
  return x
df_m_scout["Hour"] =  df_m_scout["Hour"].apply(lambda x: int_none_to_zero(x))
df_m_scout["Hour"] =  df_m_scout["Hour"].apply(lambda x: int(x))
df_m_scout = df_m_scout[df_m_scout["Hour"] > 0]
df_max_Hour = df_m_scout.groupby("Hour")["Hour"].count().to_frame("")
max_Hour = max(df_max_Hour[""])
maxHour = df_max_Hour[df_max_Hour[""] == max_Hour]
maxHour

"""#**Q4**"""

df_comment = df_scrubbed[["comments"]].copy()
res = re.compile('\w{7,}\s\w{7,}')
def find_pair(text):
  r = res.findall(text)
  return len(r)
df_comment["comments"] = df_comment["comments"].apply(lambda x: str(x))
df_comment["pairs"] = df_comment["comments"].apply(lambda x: find_pair(x))
max_comment = max(df_comment["pairs"])
max_len_comment = df_comment[df_comment["pairs"] == max_comment]
max_len_comment

"""#**Q5**"""

df_number = df_scrubbed[["country", "comments"]].copy()
res = re.compile('\d{6}')
def find_num(text):
  r = res.findall(text)
  return len(r)
df_number["comments"] = df_number["comments"].apply(lambda x: str(x))
df_number["numbers"] = df_number["comments"].apply(lambda x: find_num(x))
df_sum= df_number.groupby("country")["numbers"].sum().to_frame("")
max_comment = max(df_sum[""])
max_len_comment = df_sum[df_sum[""] == max_comment]
max_len_comment

"""#**Q6**"""

df_sequance = df_scrubbed[["comments"]].copy()
res = re.compile('\w{2}\d{1}\w{1}')
def find_sequance(text):
  r = res.findall(text)
  if not r:
    return 0
  return r
df_sequance["sequance"] = df_sequance["comments"].apply(lambda x: str(x))
df_sequance["sequance"] = df_sequance["sequance"].apply(lambda x: find_sequance(x))
df_sequance1 = df_sequance[df_sequance["sequance"] != 0]
df_sequance1